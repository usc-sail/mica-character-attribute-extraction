{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import unidecode\n",
    "import re\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Levenshtein\n",
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "import tqdm\n",
    "import random\n",
    "import unidecode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBTI => (<class 'list'>) 3543 elements\n",
      "keys@ele = dict_keys(['id', 'mbti_profile', 'subcategory', 'vote_count_mbti', 'I', 'N', 'F', 'P', 'E', 'S', 'T', 'J', 'dialog_text', 'scene_text', 'mention_text'])\n",
      "\n",
      "BIG5 => (<class 'list'>) 4184 elements\n",
      "keys@ele = dict_keys(['id', 'mbti_profile', 'subcategory', 'vote_count_mbti', 'R', 'C', 'U', 'A', 'I', 'L', 'S', 'E', 'N', 'O', 'dialog_text', 'scene_text', 'mention_text'])\n",
      "\n",
      "BOOK => (<class 'pandas.core.frame.DataFrame'>) 644425 elements\n",
      "columns = Index(['title', 'book_id', 'predsWithTitle', 'NER_title', 'NER_text', 'text'], dtype='object')\n",
      "\n",
      "HERO => (<class 'pandas.core.frame.DataFrame'>) 37776 elements\n",
      "columns = Index(['id', 'mbti_profile', 'subcategory', 'vote_count_mbti', 'I', 'N', 'F',\n",
      "       'P', 'E', 'S', 'T', 'J'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "mbti_file = os.path.join(os.getenv(\"DATA_DIR\"), \"narrative_understanding/chatter/personality/mbti.pkl\")\n",
    "big5_file = os.path.join(os.getenv(\"DATA_DIR\"), \"narrative_understanding/chatter/personality/big5.pkl\")\n",
    "book_qa_file = os.path.join(os.getenv(\"DATA_DIR\"), \n",
    "                            \"narrative_understanding/Story2Personality/preprocessed/bookQA_NER_add_space.pkl\")\n",
    "movie_superhero_file = os.path.join(os.getenv(\"DATA_DIR\"), \n",
    "                                    \"narrative_understanding/Story2Personality/preprocessed/Movie_superhero.pkl\")\n",
    "\n",
    "mbti_data = pickle.load(open(mbti_file, \"rb\"))\n",
    "big5_data = pickle.load(open(big5_file, \"rb\"))\n",
    "book_df = pickle.load(open(book_qa_file, \"rb\"))\n",
    "hero_df = pickle.load(open(movie_superhero_file, \"rb\"))\n",
    "\n",
    "print(f\"MBTI => ({type(mbti_data)}) {len(mbti_data)} elements\\nkeys@ele = {mbti_data[0].keys()}\\n\")\n",
    "print(f\"BIG5 => ({type(big5_data)}) {len(big5_data)} elements\\nkeys@ele = {big5_data[0].keys()}\\n\")\n",
    "print(f\"BOOK => ({type(book_df)}) {len(book_df)} elements\\ncolumns = {book_df.columns}\\n\")\n",
    "print(f\"HERO => ({type(hero_df)}) {len(hero_df)} elements\\ncolumns = {hero_df.columns}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get movie titles and characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbti    => 507 titles, 3504 characters\n",
      "hero    => 4957 titles, 37484 characters\n",
      "scripts => 2626 titles, 137290 characters\n",
      "\n",
      "exact match =>\n",
      "0 mbti characters absent from hero\n",
      "1386 (28.0%)  hero titles found in scripts\n",
      "6426 (17.1%) hero characters found in scripts\n"
     ]
    }
   ],
   "source": [
    "mbti_titles, mbti_title_and_characters = set(), set()\n",
    "hero_titles, hero_title_and_characters = set(), set()\n",
    "script_titles, script_title_and_characters = set(), set()\n",
    "\n",
    "def norm(text):\n",
    "    norm_text = re.sub(\"\\s+\", \" \", text).lower().strip()\n",
    "    return unidecode.unidecode(norm_text)\n",
    "\n",
    "for rec in mbti_data:\n",
    "    mbti_titles.add(norm(rec[\"subcategory\"]))\n",
    "    mbti_title_and_characters.add((norm(rec[\"subcategory\"]), norm(rec[\"mbti_profile\"])))\n",
    "\n",
    "for _, row in hero_df.iterrows():\n",
    "    hero_titles.add(norm(row[\"subcategory\"]))\n",
    "    hero_title_and_characters.add((norm(row[\"subcategory\"]), norm(row[\"mbti_profile\"])))\n",
    "\n",
    "scripts_dir = os.path.join(os.getenv(\"DATA_DIR\"), \"narrative_understanding/chatter/scripts\")\n",
    "for imdb_id in os.listdir(scripts_dir):\n",
    "    imdb_file = os.path.join(scripts_dir, imdb_id, \"imdb.json\")\n",
    "    if os.path.exists(imdb_file):\n",
    "        imdb_data = json.load(open(imdb_file))\n",
    "        title = norm(imdb_data[\"title\"])\n",
    "        script_titles.add(title)\n",
    "        if \"cast\" in imdb_data:\n",
    "            for person in imdb_data[\"cast\"]:\n",
    "                if isinstance(person.get(\"character\", None), str):\n",
    "                    name = norm(person[\"character\"])\n",
    "                    script_title_and_characters.add((title, name))\n",
    "\n",
    "print(f\"mbti    => {len(mbti_titles)} titles, {len(mbti_title_and_characters)} characters\")\n",
    "print(f\"hero    => {len(hero_titles)} titles, {len(hero_title_and_characters)} characters\")\n",
    "print(f\"scripts => {len(script_titles)} titles, {len(script_title_and_characters)} characters\\n\")\n",
    "\n",
    "print(\"exact match =>\")\n",
    "print(f\"{len(mbti_title_and_characters.difference(hero_title_and_characters))} mbti characters absent from hero\")\n",
    "\n",
    "n = len(hero_titles.intersection(script_titles))\n",
    "percent = 100*n/len(hero_titles)\n",
    "print(f\"{n} ({percent:.1f}%)  hero titles found in scripts\")\n",
    "\n",
    "n = len(hero_title_and_characters.intersection(script_title_and_characters))\n",
    "percent = 100*n/len(hero_title_and_characters)\n",
    "print(f\"{n} ({percent:.1f}%) hero characters found in scripts\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzzy matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "legally blondes => ['legally blonde']\n",
      "cinderella => ['cinderella man']\n",
      "malibu’s most wanted => [\"malibu's most wanted\"]\n",
      "rosemary’s baby => [\"rosemary's baby\"]\n",
      "battle: los angeles => ['battle los angeles']\n",
      "jurassic park / jurassic world => ['the lost world: jurassic park']\n",
      "it’s complicated => [\"it's complicated\"]\n",
      "expendables => ['the expendables']\n",
      "13 hours => ['13/13/13']\n",
      "willy wonka and the chocolate factory => ['willy wonka & the chocolate factory']\n"
     ]
    }
   ],
   "source": [
    "hero_titles_notin_script = hero_titles.difference(script_titles)\n",
    "cutoff = 95\n",
    "i = 0\n",
    "\n",
    "for hero_title in hero_titles_notin_script:\n",
    "    closest_script_titles_and_scores = process.extract(hero_title, script_titles, limit=5)\n",
    "    closest_script_titles = [title for title, score in closest_script_titles_and_scores if score >= cutoff]\n",
    "    if closest_script_titles:\n",
    "        print(f\"{hero_title} => {closest_script_titles}\")\n",
    "        i += 1\n",
    "        if i == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4961"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hero_df.groupby(\"subcategory\").ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "story",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
